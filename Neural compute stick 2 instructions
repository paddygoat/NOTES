https://software.intel.com/en-us/neural-compute-stick/get-started    ..... instructions page
https://software.seek.intel.com/openvino-toolkit   ...... download page

sudo apt-get update && sudo apt-get upgrade
cd ~/Downloads

tar xvf l_openvino_toolkit_p_2018.5.445.tgz
cd l_openvino_toolkit_p_2018.5.445
sudo -E ./install_cv_sdk_dependencies.sh
sudo ./install_GUI.sh

sudo -E ./install_cv_sdk_dependencies.sh

cd ~/Downloads

Be careful to copy this code block properly:

cat <<EOF > 97-usbboot.rules
SUBSYSTEM=="usb", ATTRS{idProduct}=="2150", ATTRS{idVendor}=="03e7", GROUP="users", MODE="0666", ENV{ID_MM_DEVICE_IGNORE}="1"
SUBSYSTEM=="usb", ATTRS{idProduct}=="2485", ATTRS{idVendor}=="03e7", GROUP="users", MODE="0666", ENV{ID_MM_DEVICE_IGNORE}="1"
SUBSYSTEM=="usb", ATTRS{idProduct}=="f63b", ATTRS{idVendor}=="03e7", GROUP="users", MODE="0666", ENV{ID_MM_DEVICE_IGNORE}="1"
EOF


sudo cp 97-usbboot.rules /etc/udev/rules.d/
sudo udevadm control --reload-rules
sudo udevadm trigger
sudo ldconfig
rm 97-usbboot.rules

error: /sbin/ldconfig.real: /opt/intel/mediasdk/lib64/libmfx.so.1 is not a symbolic link

sudo usermod -a -G users "$(whoami)"
cat <<EOF > 97-myriad-usbboot.rules
SUBSYSTEM=="usb", ATTRS{idProduct}=="2150", ATTRS{idVendor}=="03e7", GROUP="users", MODE="0666", ENV{ID_MM_DEVICE_IGNORE}="1"
SUBSYSTEM=="usb", ATTRS{idProduct}=="2485", ATTRS{idVendor}=="03e7", GROUP="users", MODE="0666", ENV{ID_MM_DEVICE_IGNORE}="1"
SUBSYSTEM=="usb", ATTRS{idProduct}=="f63b", ATTRS{idVendor}=="03e7", GROUP="users", MODE="0666", ENV{ID_MM_DEVICE_IGNORE}="1"
EOF
sudo cp 97-myriad-usbboot.rules /etc/udev/rules.d/
sudo udevadm control --reload-rules
sudo udevadm trigger
sudo ldconfig
rm 97-myriad-usbboot.rules
OR:
cd <INSTALL_DIR>/install_dependencies/
./install_NCS_udev_rules.sh
cd /opt/intel/computer_vision_sdk/install_dependencies && ./install_NCS_udev_rules.sh

###### Must be in computer_vision_sdk_2018.5.445 folder !!!!!

Please setup your environment. Run 'source <OVINO_INSTALLDIR>/bin/setupvars.sh'.
cd /opt/intel/computer_vision_sdk_2018.5.445/bin/ && ./setupvars.sh

sudo apt install libusb-1.0-0 libboost-program-options1.58.0 libboost-thread1.58.0 libboost-filesystem1.58.0 libssl1.0.0 libudev1 libjson-c2

Error: /sbin/ldconfig.real: /opt/intel/mediasdk/lib64/libmfxhw64.so.1 is not a symbolic link
sudo usermod -a -G users "$(whoami)"


source /opt/intel/computer_vision_sdk/bin/setupvars.sh
vi etc/.bashrc
source /opt/intel/computer_vision_sdk/bin/setupvars.sh

..... Could not complete this step

cd /opt/intel/computer_vision_sdk/deployment_tools/model_optimizer/install_prerequisites
sudo ./install_prerequisites.sh



TEST with image calssification:

cd /opt/intel/computer_vision_sdk/deployment_tools/model_optimizer/install_prerequisites
./install_prerequisites.sh

REBOOT !!!

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/demo/
./demo_squeezenet_download_convert_run.sh

cd /opt/intel/computer_vision_sdk/deployment_tools/demo
./demo_squeezenet_download_convert_run.sh -d MYRIAD
./demo_squeezenet_download_convert_run.sh -d CPU
....... Only works in CPU mode.


Labels:
cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/person-vehicle-bike-detection-crossroad-0078/FP16/
sudo cp /home/tegwyn/Desktop/person-vehicle-bike-detection-crossroad-0078.labels /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/person-vehicle-bike-detection-crossroad-0078/FP16/

sudo cat > labels.labels
ls -l labels.labels
vi labels.labels


cd /home/tegwyn/inference_engine_samples/interactive_face_detection_demo
make install
..... Now got to: inference_engine_samples/intel64/Release
cd ~/inference_engine_samples/intel64/Release
./interactive_face_detection_demo.sh -d MYRIAD

Face, Emotion, Age, Gender, and Pose Detection example:



./interactive_face_detection_demo -d MYRIAD -m /opt/intel/computer_vision_sdk/deployment_tools/intel_models/face-detection-retail-0004/FP16/face-detection-retail-0004.xml -d_ag MYRIAD -m_ag /opt/intel/computer_vision_sdk/deployment_tools/intel_models/age-gender-recognition-retail-0013/FP16/age-gender-recognition-retail-0013.xml -d_em MYRIAD -m_em /opt/intel/computer_vision_sdk/deployment_tools/intel_models/emotions-recognition-retail-0003/FP16/emotions-recognition-retail-0003.xml -d_hp MYRIAD -m_hp /opt/intel/computer_vision_sdk/deployment_tools/intel_models/head-pose-estimation-adas-0001/FP16/head-pose-estimation-adas-0001.xml    ............ WORKS !!!!!!

cd ~/inference_engine_samples/intel64/Release

./interactive_face_detection_demo -d MYRIAD -m /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/face-detection-retail-0004/FP16/face-detection-retail-0004.xml -d_ag MYRIAD -m_ag /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/age-gender-recognition-retail-0013/FP16/age-gender-recognition-retail-0013.xml -d_em MYRIAD -m_em /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/emotions-recognition-retail-0003/FP16/emotions-recognition-retail-0003.xml -d_hp MYRIAD -m_hp /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/head-pose-estimation-adas-0001/FP16/head-pose-estimation-adas-0001.xml  ............ WORKS on new install.

computer_vision_sdk_2018.5.445

cd /opt/intel/computer_vision_sdk/deployment_tools/intel_models/head-pose-estimation-adas-0001/FP16/
cd opt/intel/computer_vision_sdk/deployment_tools/intel_models/


[ ERROR ] Error loading xmlfile: opt/intel/computer_vision_sdk/deployment_tools/intel_models/head-pose-estimation-adas-0001/FP16/head-pose-estimation-adas-0001.xml

/home/tegwyn/intel/computer_vision_sdk/deployment_tools/intel_models/face-detection-retail-0004/FP16/face-detection-retail-0004.xml

/opt/intel/computer_vision_sdk/deployment_tools/intel_models/face-detection-retail-0004/FP16/face-detection-retail-0004.xml

Person detector:

cd /home/tegwyn/inference_engine_samples/object_detection_sample_ssd
make install
..... Now got to: inference_engine_samples/intel64/Release
cd ~/inference_engine_samples/intel64/Release
./object_detection_demo_ssd_async -d MYRIAD -i cam -m /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/person-detection-retail-0013/FP16/person-detection-retail-0013.xml


cd /home/tegwyn/inference_engine_samples/human_pose_estimation_demo
make install
..... Now got to: inference_engine_samples/intel64/Release
cd ~/inference_engine_samples/intel64/Release
..... Then:
./human_pose_estimation_demo -d MYRIAD -i cam -m /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/human-pose-estimation-0001/FP16/human-pose-estimation-0001.xml
.... FAILED !!!!!

cd /home/tegwyn/inference_engine_samples/object_detection_demo_ssd_async/
make install
cd ~/inference_engine_samples/intel64/Release
./object_detection_demo_ssd_async -d MYRIAD -i cam -m /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/person-vehicle-bike-detection-crossroad-0078/FP16/person-vehicle-bike-detection-crossroad-0078.xml

source /opt/intel/computer_vision_sdk/bin/setupvars.sh

cd ~/inference_engine_samples/intel64/Release

./interactive_face_detection_demo -i /home/tegwyn/Desktop/avatar.bmp -d MYRIAD -m /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/face-detection-retail-0004/FP16/face-detection-retail-0004.xml -d_ag MYRIAD -m_ag /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/age-gender-recognition-retail-0013/FP16/age-gender-recognition-retail-0013.xml -d_em MYRIAD -m_em /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/emotions-recognition-retail-0003/FP16/emotions-recognition-retail-0003.xml -d_hp MYRIAD -m_hp /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/head-pose-estimation-adas-0001/FP16/head-pose-estimation-adas-0001.xml

sudo rm /dev/video0
ls -ltr /dev/video*
sudo mv /dev/video1 /dev/video0

gst-launch-1.0 -e icamerasrc device-name=0 io-mode=3 ! video/x-raw,format=NV12,width=640,height=480,framerate=30/1 ! vaapih264enc tune=low-power dmabuf-alloc-tiled=true ! h264parse ! mp4mux ! filesink location=test.mp4

sudo apt-get install v4l-utils
v4l2-ctl
v4l2-ctl --help-vidout
v4l2-ctl --list-fields-out

v4l2-ctl --list-formats-out
v4l2-ctl --get-fmt-video-out

v4l2-ctl --try-fmt-video-out=width=<640>,height=<480>


cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/ && sudo chmod 777 model_optimizer
cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_caffe.py --input_model /home/tegwyn/Desktop/wasp/snapshot_iter_63300.caffemodel
python3 mo.py --input_model /home/tegwyn/Desktop/wasp/snapshot_iter_63300.caffemodel
python3 mo.py --input_model /home/tegwyn/Desktop/wasp/snapshot_iter_63300.caffemodel --input_shape [1,3,640,640]
 --input_shape (1,3,227,227)
/home/tegwyn/Desktop/TRAIN227/snapshot_iter_71800.caffemodel
python3 mo_caffe.py --input_model /home/tegwyn/Desktop/TRAIN227/snapshot_iter_71800.caffemodel --log_level=DEBUG

python3 mo.py --input_model /home/tegwyn/Desktop/TRAIN227/snapshot_iter_71800.caffemodel

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_caffe.py --input_model /home/tegwyn/Desktop/wasp_mobileSSD/VGG_VOC0712_SSD_300x300_iter_80000.caffemodel

VGG_VOC0712_SSD_300x300_iter_80000.prototxt 

[ SUCCESS ] Generated IR model.
[ SUCCESS ] XML file: /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/./VGG_VOC0712_SSD_300x300_iter_80000.xml
[ SUCCESS ] BIN file: /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/./VGG_VOC0712_SSD_300x300_iter_80000.bin
[ SUCCESS ] Total execution time: 17.12 seconds. 

cd /home/tegwyn/inference_engine_samples/object_detection_sample_ssd
make install
..... Now got to: inference_engine_samples/intel64/Release
cd ~/inference_engine_samples/intel64/Release
./object_detection_demo_ssd_async -d MYRIAD -i cam -m /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/person-detection-retail-0013/FP16/person-detection-retail-0013.xml

/home/tegwyn/Desktop/wasp_mobileSSD/VGG_VOC0712_SSD_300x300_iter_80000.xml

cd ~/inference_engine_samples/intel64/Release
./object_detection_demo_ssd_async -d MYRIAD -i cam -m /home/tegwyn/Desktop/wasp_mobileSSD/VGG_VOC0712_SSD_300x300_iter_80000.xml

[ ERROR ] [VPU] Unsupported network precision : FP32

cd ~/inference_engine_samples/intel64/Release
./object_detection_demo_ssd_async -d CPU -i cam -m /home/tegwyn/Desktop/wasp_mobileSSD/VGG_VOC0712_SSD_300x300_iter_80000.xml

For example, I tried something similar to "./ModelOptimizer -p FP32 -w $MODEL_DIR/bvlc_alexnet.caffemodel -d $MODEL_DIR/deploy.prototxt -i -b 1", the FP32 model is generated successfully and works in Inference Engine. 

  --data_type {FP16,FP32,half,float} Data type for all intermediate tensors and weights. 
If original model is in FP32 and --data_type=FP16 is specified, all model weights and biases are quantized to FP16.

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_caffe.py --data_type=FP16 --input_model /home/tegwyn/Desktop/wasp_mobileSSD/VGG_VOC0712_SSD_300x300_iter_80000.caffemodel

cd ~/inference_engine_samples/intel64/Release
./object_detection_demo_ssd_async -d MYRIAD -i cam -m /home/tegwyn/Desktop/wasp_mobileSSD/VGG_VOC0712_SSD_300x300_iter_80000.xml  ...... WORKS!!!!!!

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_caffe.py --data_type=FP16 --input_shape [1,3,227,227] --input_model /home/tegwyn/Desktop/TRAIN227/snapshot_iter_71800.caffemodel  ...... NOT WORKING!

 --data_type=FP16
	optional arguments:
  -h, --help            show this help message and exit
  --framework {tf,caffe,mxnet,kaldi,onnx}
                        Name of the framework used to train the input model.

Framework-agnostic parameters:
  --input_model INPUT_MODEL, -w INPUT_MODEL, -m INPUT_MODEL
                        Tensorflow*: a file with a pre-trained model (binary
                        or text .pb file after freezing). Caffe*: a model
                        proto file with model weights
  --model_name MODEL_NAME, -n MODEL_NAME
                        Model_name parameter passed to the final create_ir
                        transform. This parameter is used to name a network in
                        a generated IR and output .xml/.bin files.
  --output_dir OUTPUT_DIR, -o OUTPUT_DIR
                        Directory that stores the generated IR. By default, it
                        is the directory from where the Model Optimizer is
                        launched.
  --input_shape INPUT_SHAPE
                        Input shape(s) that should be fed to an input node(s)
                        of the model. Shape is defined as a comma-separated
                        list of integer numbers enclosed in parentheses or
                        square brackets, for example [1,3,227,227] or
                        (1,227,227,3), where the order of dimensions depends
                        on the framework input layout of the model. For
                        example, [N,C,H,W] is used for Caffe* models and
                        [N,H,W,C] for TensorFlow* models. Model Optimizer
                        performs necessary transformations to convert the
                        shape to the layout required by Inference Engine
                        (N,C,H,W). The shape should not contain undefined
                        dimensions (? or -1) and should fit the dimensions
                        defined in the input operation of the graph. If there
                        are multiple inputs in the model, --input_shape should
                        contain definition of shape for each input separated
                        by a comma, for example: [1,3,227,227],[2,4] for a
                        model with two inputs with 4D and 2D shapes.
  --scale SCALE, -s SCALE
                        All input values coming from original network inputs
                        will be divided by this value. When a list of inputs
                        is overridden by the --input parameter, this scale is
                        not applied for any input that does not match with the
                        original input of the model.
  --reverse_input_channels
                        Switch the input channels order from RGB to BGR (or
                        vice versa). Applied to original inputs of the model
                        if and only if a number of channels equals 3. Applied
                        after application of --mean_values and --scale_values
                        options, so numbers in --mean_values and
                        --scale_values go in the order of channels used in the
                        original model.
  --log_level {CRITICAL,ERROR,WARN,WARNING,INFO,DEBUG,NOTSET}
                        Logger level
  --input INPUT         The name of the input operation of the given model.
                        Usually this is a name of the input placeholder of the
                        model.
  --output OUTPUT       The name of the output operation of the model. For
                        TensorFlow*, do not add :0 to this name.
  --mean_values MEAN_VALUES, -ms MEAN_VALUES
                        Mean values to be used for the input image per
                        channel. Values to be provided in the (R,G,B) or
                        [R,G,B] format. Can be defined for desired input of
                        the model, for example: "--mean_values
                        data[255,255,255],info[255,255,255]". The exact
                        meaning and order of channels depend on how the
                        original model was trained.
  --scale_values SCALE_VALUES
                        Scale values to be used for the input image per
                        channel. Values are provided in the (R,G,B) or [R,G,B]
                        format. Can be defined for desired input of the model,
                        for example: "--scale_values
                        data[255,255,255],info[255,255,255]". The exact
                        meaning and order of channels depend on how the
                        original model was trained.
  --data_type {FP16,FP32,half,float}
                        Data type for all intermediate tensors and weights. If
                        original model is in FP32 and --data_type=FP16 is
                        specified, all model weights and biases are quantized
                        to FP16.
  --disable_fusing      Turn off fusing of linear operations to Convolution
  --disable_resnet_optimization
                        Turn off resnet optimization
  --finegrain_fusing FINEGRAIN_FUSING
                        Regex for layers/operations that won't be fused.
                        Example: --finegrain_fusing Convolution1,.*Scale.*
  --disable_gfusing     Turn off fusing of grouped convolutions
  --move_to_preprocess  Move mean values to IR preprocess section
  --extensions EXTENSIONS
                        Directory or a comma separated list of directories
                        with extensions. To disable all extensions including
                        those that are placed at the default location, pass an
                        empty string.
  --batch BATCH, -b BATCH
                        Input batch size
  --version             Version of Model Optimizer
  --silent              Prevent any output messages except those that
                        correspond to log level equals ERROR, that can be set
                        with the following option: --log_level. By default,
                        log level is already ERROR.
  --freeze_placeholder_with_value FREEZE_PLACEHOLDER_WITH_VALUE
                        Replaces input layer with constant node with provided
                        value, e.g.: "node_name->True"
  --generate_deprecated_IR_V2
                        Force to generate legacy/deprecated IR V2 to work with
                        previous versions of the Inference Engine. The
                        resulting IR may or may not be correctly loaded by
                        Inference Engine API (including the most recent and
                        old versions of Inference Engine) and provided as a
                        partially-validated backup option for specific
                        deployment scenarios. Use it at your own discretion.
                        By default, without this option, the Model Optimizer
                        generates IR V3.







