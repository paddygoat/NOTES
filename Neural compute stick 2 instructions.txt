https://software.intel.com/en-us/neural-compute-stick/get-started    ..... instructions page
https://software.seek.intel.com/openvino-toolkit   ...... download page

sudo apt-get update && sudo apt-get upgrade
cd ~/Downloads

tar xvf l_openvino_toolkit_p_2018.5.445.tgz
cd l_openvino_toolkit_p_2018.5.445
sudo -E ./install_cv_sdk_dependencies.sh
sudo ./install_GUI.sh

sudo -E ./install_cv_sdk_dependencies.sh

cd ~/Downloads

Be careful to copy this code block properly:

cat <<EOF > 97-usbboot.rules
SUBSYSTEM=="usb", ATTRS{idProduct}=="2150", ATTRS{idVendor}=="03e7", GROUP="users", MODE="0666", ENV{ID_MM_DEVICE_IGNORE}="1"
SUBSYSTEM=="usb", ATTRS{idProduct}=="2485", ATTRS{idVendor}=="03e7", GROUP="users", MODE="0666", ENV{ID_MM_DEVICE_IGNORE}="1"
SUBSYSTEM=="usb", ATTRS{idProduct}=="f63b", ATTRS{idVendor}=="03e7", GROUP="users", MODE="0666", ENV{ID_MM_DEVICE_IGNORE}="1"
EOF


sudo cp 97-usbboot.rules /etc/udev/rules.d/
sudo udevadm control --reload-rules
sudo udevadm trigger
sudo ldconfig
rm 97-usbboot.rules

error: /sbin/ldconfig.real: /opt/intel/mediasdk/lib64/libmfx.so.1 is not a symbolic link

sudo usermod -a -G users "$(whoami)"
cat <<EOF > 97-myriad-usbboot.rules
SUBSYSTEM=="usb", ATTRS{idProduct}=="2150", ATTRS{idVendor}=="03e7", GROUP="users", MODE="0666", ENV{ID_MM_DEVICE_IGNORE}="1"
SUBSYSTEM=="usb", ATTRS{idProduct}=="2485", ATTRS{idVendor}=="03e7", GROUP="users", MODE="0666", ENV{ID_MM_DEVICE_IGNORE}="1"
SUBSYSTEM=="usb", ATTRS{idProduct}=="f63b", ATTRS{idVendor}=="03e7", GROUP="users", MODE="0666", ENV{ID_MM_DEVICE_IGNORE}="1"
EOF
sudo cp 97-myriad-usbboot.rules /etc/udev/rules.d/
sudo udevadm control --reload-rules
sudo udevadm trigger
sudo ldconfig
rm 97-myriad-usbboot.rules
OR:
cd <INSTALL_DIR>/install_dependencies/
./install_NCS_udev_rules.sh
cd /opt/intel/computer_vision_sdk/install_dependencies && ./install_NCS_udev_rules.sh

###### Must be in computer_vision_sdk_2018.5.445 folder !!!!!

Please setup your environment. Run 'source <OVINO_INSTALLDIR>/bin/setupvars.sh'.
cd /opt/intel/computer_vision_sdk_2018.5.445/bin/ && ./setupvars.sh

sudo apt install libusb-1.0-0 libboost-program-options1.58.0 libboost-thread1.58.0 libboost-filesystem1.58.0 libssl1.0.0 libudev1 libjson-c2

Error: /sbin/ldconfig.real: /opt/intel/mediasdk/lib64/libmfxhw64.so.1 is not a symbolic link
sudo usermod -a -G users "$(whoami)"


source /opt/intel/computer_vision_sdk/bin/setupvars.sh
vi etc/.bashrc
source /opt/intel/computer_vision_sdk/bin/setupvars.sh

..... Could not complete this step

cd /opt/intel/computer_vision_sdk/deployment_tools/model_optimizer/install_prerequisites
sudo ./install_prerequisites.sh



TEST with image calssification:

cd /opt/intel/computer_vision_sdk/deployment_tools/model_optimizer/install_prerequisites
./install_prerequisites.sh

REBOOT !!!

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/demo/
./demo_squeezenet_download_convert_run.sh

cd /opt/intel/computer_vision_sdk/deployment_tools/demo
./demo_squeezenet_download_convert_run.sh -d MYRIAD
./demo_squeezenet_download_convert_run.sh -d CPU
....... Only works in CPU mode.


Labels:
cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/person-vehicle-bike-detection-crossroad-0078/FP16/
sudo cp /home/tegwyn/Desktop/person-vehicle-bike-detection-crossroad-0078.labels /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/person-vehicle-bike-detection-crossroad-0078/FP16/

sudo cat > labels.labels
ls -l labels.labels
vi labels.labels


cd /home/tegwyn/inference_engine_samples/interactive_face_detection_demo
make install
..... Now got to: inference_engine_samples/intel64/Release
cd ~/inference_engine_samples/intel64/Release
./interactive_face_detection_demo.sh -d MYRIAD

Face, Emotion, Age, Gender, and Pose Detection example:



./interactive_face_detection_demo -d MYRIAD -m /opt/intel/computer_vision_sdk/deployment_tools/intel_models/face-detection-retail-0004/FP16/face-detection-retail-0004.xml -d_ag MYRIAD -m_ag /opt/intel/computer_vision_sdk/deployment_tools/intel_models/age-gender-recognition-retail-0013/FP16/age-gender-recognition-retail-0013.xml -d_em MYRIAD -m_em /opt/intel/computer_vision_sdk/deployment_tools/intel_models/emotions-recognition-retail-0003/FP16/emotions-recognition-retail-0003.xml -d_hp MYRIAD -m_hp /opt/intel/computer_vision_sdk/deployment_tools/intel_models/head-pose-estimation-adas-0001/FP16/head-pose-estimation-adas-0001.xml    ............ WORKS !!!!!!

cd ~/inference_engine_samples/intel64/Release

./interactive_face_detection_demo -d MYRIAD -m /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/face-detection-retail-0004/FP16/face-detection-retail-0004.xml -d_ag MYRIAD -m_ag /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/age-gender-recognition-retail-0013/FP16/age-gender-recognition-retail-0013.xml -d_em MYRIAD -m_em /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/emotions-recognition-retail-0003/FP16/emotions-recognition-retail-0003.xml -d_hp MYRIAD -m_hp /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/head-pose-estimation-adas-0001/FP16/head-pose-estimation-adas-0001.xml  ............ WORKS on new install.

computer_vision_sdk_2018.5.445

cd /opt/intel/computer_vision_sdk/deployment_tools/intel_models/head-pose-estimation-adas-0001/FP16/
cd opt/intel/computer_vision_sdk/deployment_tools/intel_models/


[ ERROR ] Error loading xmlfile: opt/intel/computer_vision_sdk/deployment_tools/intel_models/head-pose-estimation-adas-0001/FP16/head-pose-estimation-adas-0001.xml

/home/tegwyn/intel/computer_vision_sdk/deployment_tools/intel_models/face-detection-retail-0004/FP16/face-detection-retail-0004.xml

/opt/intel/computer_vision_sdk/deployment_tools/intel_models/face-detection-retail-0004/FP16/face-detection-retail-0004.xml

Person detector:

cd /home/tegwyn/inference_engine_samples/object_detection_sample_ssd
make install
..... Now got to: inference_engine_samples/intel64/Release
cd ~/inference_engine_samples/intel64/Release
./object_detection_demo_ssd_async -d MYRIAD -i cam -m /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/person-detection-retail-0013/FP16/person-detection-retail-0013.xml


cd /home/tegwyn/inference_engine_samples/human_pose_estimation_demo
make install
..... Now got to: inference_engine_samples/intel64/Release
cd ~/inference_engine_samples/intel64/Release
..... Then:
./human_pose_estimation_demo -d MYRIAD -i cam -m /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/human-pose-estimation-0001/FP16/human-pose-estimation-0001.xml
.... FAILED !!!!!

cd /home/tegwyn/inference_engine_samples/object_detection_demo_ssd_async/
make install
cd ~/inference_engine_samples/intel64/Release
./object_detection_demo_ssd_async -d MYRIAD -i cam -m /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/person-vehicle-bike-detection-crossroad-0078/FP16/person-vehicle-bike-detection-crossroad-0078.xml

source /opt/intel/computer_vision_sdk/bin/setupvars.sh

cd ~/inference_engine_samples/intel64/Release

./interactive_face_detection_demo -i /home/tegwyn/Desktop/avatar.bmp -d MYRIAD -m /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/face-detection-retail-0004/FP16/face-detection-retail-0004.xml -d_ag MYRIAD -m_ag /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/age-gender-recognition-retail-0013/FP16/age-gender-recognition-retail-0013.xml -d_em MYRIAD -m_em /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/emotions-recognition-retail-0003/FP16/emotions-recognition-retail-0003.xml -d_hp MYRIAD -m_hp /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/head-pose-estimation-adas-0001/FP16/head-pose-estimation-adas-0001.xml

cd ~/inference_engine_samples/intel64/Release
./security_barrier_camera_demo -i cam -m vehicle-license-plate-detection-barrier-0106.xml -m_va vehicle-attributes-recognition-barrier-0039.xml -m_lpr license-plate-recognition-barrier-0001.xml -d MYRIAD

cd ~/inference_engine_samples/intel64/Release
./security_barrier_camera_demo -i /home/tegwyn/Videos/car.mp4 -m vehicle-license-plate-detection-barrier-0106.xml -m_va vehicle-attributes-recognition-barrier-0039.xml -m_lpr license-plate-recognition-barrier-0001.xml -d GPU

sudo rm /dev/video0
ls -ltr /dev/video*
sudo mv /dev/video1 /dev/video0

gst-launch-1.0 -e icamerasrc device-name=0 io-mode=3 ! video/x-raw,format=NV12,width=640,height=480,framerate=30/1 ! vaapih264enc tune=low-power dmabuf-alloc-tiled=true ! h264parse ! mp4mux ! filesink location=test.mp4

sudo apt-get install v4l-utils
v4l2-ctl
v4l2-ctl --help-vidout
v4l2-ctl --list-fields-out

v4l2-ctl --list-formats-out
v4l2-ctl --get-fmt-video-out

v4l2-ctl --try-fmt-video-out=width=<640>,height=<480>


cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/ && sudo chmod 777 model_optimizer
cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_caffe.py --input_model /home/tegwyn/Desktop/wasp/snapshot_iter_63300.caffemodel
python3 mo.py --input_model /home/tegwyn/Desktop/wasp/snapshot_iter_63300.caffemodel
python3 mo.py --input_model /home/tegwyn/Desktop/wasp/snapshot_iter_63300.caffemodel --input_shape [1,3,640,640]
 --input_shape (1,3,227,227)
/home/tegwyn/Desktop/TRAIN227/snapshot_iter_71800.caffemodel
python3 mo_caffe.py --input_model /home/tegwyn/Desktop/TRAIN227/snapshot_iter_71800.caffemodel --log_level=DEBUG

python3 mo.py --input_model /home/tegwyn/Desktop/TRAIN227/snapshot_iter_71800.caffemodel

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_caffe.py --input_model /home/tegwyn/Desktop/wasp_mobileSSD/VGG_VOC0712_SSD_300x300_iter_80000.caffemodel

VGG_VOC0712_SSD_300x300_iter_80000.prototxt 

[ SUCCESS ] Generated IR model.
[ SUCCESS ] XML file: /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/./VGG_VOC0712_SSD_300x300_iter_80000.xml
[ SUCCESS ] BIN file: /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/./VGG_VOC0712_SSD_300x300_iter_80000.bin
[ SUCCESS ] Total execution time: 17.12 seconds. 

cd /home/tegwyn/inference_engine_samples/object_detection_sample_ssd
make install
..... Now got to: inference_engine_samples/intel64/Release
cd ~/inference_engine_samples/intel64/Release
./object_detection_demo_ssd_async -d MYRIAD -i cam -m /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/person-detection-retail-0013/FP16/person-detection-retail-0013.xml

/home/tegwyn/Desktop/wasp_mobileSSD/VGG_VOC0712_SSD_300x300_iter_80000.xml

cd ~/inference_engine_samples/intel64/Release
./object_detection_demo_ssd_async -d MYRIAD -i cam -m /home/tegwyn/Desktop/wasp_mobileSSD/VGG_VOC0712_SSD_300x300_iter_80000.xml

[ ERROR ] [VPU] Unsupported network precision : FP32

cd ~/inference_engine_samples/intel64/Release
./object_detection_demo_ssd_async -d CPU -i cam -m /home/tegwyn/Desktop/wasp_mobileSSD/VGG_VOC0712_SSD_300x300_iter_80000.xml

For example, I tried something similar to "./ModelOptimizer -p FP32 -w $MODEL_DIR/bvlc_alexnet.caffemodel -d $MODEL_DIR/deploy.prototxt -i -b 1", the FP32 model is generated successfully and works in Inference Engine. 

  --data_type {FP16,FP32,half,float} Data type for all intermediate tensors and weights. 
If original model is in FP32 and --data_type=FP16 is specified, all model weights and biases are quantized to FP16.

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_caffe.py --data_type=FP16 --input_model /home/tegwyn/Desktop/wasp_mobileSSD/VGG_VOC0712_SSD_300x300_iter_80000.caffemodel

cd ~/inference_engine_samples/intel64/Release
./object_detection_demo_ssd_async -d MYRIAD -i cam -m /home/tegwyn/Desktop/wasp_mobileSSD/VGG_VOC0712_SSD_300x300_iter_80000.xml  ...... WORKS!!!!!!

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_caffe.py --data_type=FP16 --input_shape [1,3,227,227] --input_model /home/tegwyn/Desktop/TRAIN227/snapshot_iter_71800.caffemodel  ...... NOT WORKING!

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_caffe.py --data_type=FP16 --input_model /home/tegwyn/Desktop/TRAIN227/snapshot_iter_71800.caffemodel --log_level DEBUG  ...... NOT WORKING!

  param {
    share_mode: PERMISSIVE
  }

 --data_type=FP16
	optional arguments:
  -h, --help            show this help message and exit
  --framework {tf,caffe,mxnet,kaldi,onnx}
                        Name of the framework used to train the input model.

Framework-agnostic parameters:
  --input_model INPUT_MODEL, -w INPUT_MODEL, -m INPUT_MODEL
                        Tensorflow*: a file with a pre-trained model (binary
                        or text .pb file after freezing). Caffe*: a model
                        proto file with model weights
  --model_name MODEL_NAME, -n MODEL_NAME
                        Model_name parameter passed to the final create_ir
                        transform. This parameter is used to name a network in
                        a generated IR and output .xml/.bin files.
  --output_dir OUTPUT_DIR, -o OUTPUT_DIR
                        Directory that stores the generated IR. By default, it
                        is the directory from where the Model Optimizer is
                        launched.
  --input_shape INPUT_SHAPE
                        Input shape(s) that should be fed to an input node(s)
                        of the model. Shape is defined as a comma-separated
                        list of integer numbers enclosed in parentheses or
                        square brackets, for example [1,3,227,227] or
                        (1,227,227,3), where the order of dimensions depends
                        on the framework input layout of the model. For
                        example, [N,C,H,W] is used for Caffe* models and
                        [N,H,W,C] for TensorFlow* models. Model Optimizer
                        performs necessary transformations to convert the
                        shape to the layout required by Inference Engine
                        (N,C,H,W). The shape should not contain undefined
                        dimensions (? or -1) and should fit the dimensions
                        defined in the input operation of the graph. If there
                        are multiple inputs in the model, --input_shape should
                        contain definition of shape for each input separated
                        by a comma, for example: [1,3,227,227],[2,4] for a
                        model with two inputs with 4D and 2D shapes.
  --scale SCALE, -s SCALE
                        All input values coming from original network inputs
                        will be divided by this value. When a list of inputs
                        is overridden by the --input parameter, this scale is
                        not applied for any input that does not match with the
                        original input of the model.
  --reverse_input_channels
                        Switch the input channels order from RGB to BGR (or
                        vice versa). Applied to original inputs of the model
                        if and only if a number of channels equals 3. Applied
                        after application of --mean_values and --scale_values
                        options, so numbers in --mean_values and
                        --scale_values go in the order of channels used in the
                        original model.
  --log_level {CRITICAL,ERROR,WARN,WARNING,INFO,DEBUG,NOTSET}
                        Logger level
  --input INPUT         The name of the input operation of the given model.
                        Usually this is a name of the input placeholder of the
                        model.
  --output OUTPUT       The name of the output operation of the model. For
                        TensorFlow*, do not add :0 to this name.
  --mean_values MEAN_VALUES, -ms MEAN_VALUES
                        Mean values to be used for the input image per
                        channel. Values to be provided in the (R,G,B) or
                        [R,G,B] format. Can be defined for desired input of
                        the model, for example: "--mean_values
                        data[255,255,255],info[255,255,255]". The exact
                        meaning and order of channels depend on how the
                        original model was trained.
  --scale_values SCALE_VALUES
                        Scale values to be used for the input image per
                        channel. Values are provided in the (R,G,B) or [R,G,B]
                        format. Can be defined for desired input of the model,
                        for example: "--scale_values
                        data[255,255,255],info[255,255,255]". The exact
                        meaning and order of channels depend on how the
                        original model was trained.
  --data_type {FP16,FP32,half,float}
                        Data type for all intermediate tensors and weights. If
                        original model is in FP32 and --data_type=FP16 is
                        specified, all model weights and biases are quantized
                        to FP16.
  --disable_fusing      Turn off fusing of linear operations to Convolution
  --disable_resnet_optimization
                        Turn off resnet optimization
  --finegrain_fusing FINEGRAIN_FUSING
                        Regex for layers/operations that won't be fused.
                        Example: --finegrain_fusing Convolution1,.*Scale.*
  --disable_gfusing     Turn off fusing of grouped convolutions
  --move_to_preprocess  Move mean values to IR preprocess section
  --extensions EXTENSIONS
                        Directory or a comma separated list of directories
                        with extensions. To disable all extensions including
                        those that are placed at the default location, pass an
                        empty string.
  --batch BATCH, -b BATCH
                        Input batch size
  --version             Version of Model Optimizer
  --silent              Prevent any output messages except those that
                        correspond to log level equals ERROR, that can be set
                        with the following option: --log_level. By default,
                        log level is already ERROR.
  --freeze_placeholder_with_value FREEZE_PLACEHOLDER_WITH_VALUE
                        Replaces input layer with constant node with provided
                        value, e.g.: "node_name->True"
  --generate_deprecated_IR_V2
                        Force to generate legacy/deprecated IR V2 to work with
                        previous versions of the Inference Engine. The
                        resulting IR may or may not be correctly loaded by
                        Inference Engine API (including the most recent and
                        old versions of Inference Engine) and provided as a
                        partially-validated backup option for specific
                        deployment scenarios. Use it at your own discretion.
                        By default, without this option, the Model Optimizer
                        generates IR V3.


cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_caffe.py --data_type=FP16 --input_model /home/tegwyn/Desktop/SSD_300_WASP01/VGG_VOC0712_SSD_300x300_iter_20211.caffemodel

[ SUCCESS ] XML file: /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/./VGG_VOC0712_SSD_300x300_iter_20211.xml
[ SUCCESS ] BIN file: /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/./VGG_VOC0712_SSD_300x300_iter_20211.bin

cd ~/inference_engine_samples/intel64/Release
./object_detection_demo_ssd_async -d MYRIAD -i cam -m /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/./VGG_VOC0712_SSD_300x300_iter_20211.xml  ..... WORKS !!!!!

cd ~/inference_engine_samples/intel64/Release
./object_detection_sample_ssd -d MYRIAD -i /home/tegwyn/Desktop/wasp05.bmp -m /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/./VGG_VOC0712_SSD_300x300_iter_20211.xml ....... WORKS !!!!!!

/home/tegwyn/inference_engine_samples/intel64/Release/out_0.bmp

[0,1] element, prob = 0.99707    (25,92.5)-(574.062,548.75) batch id : 0 WILL BE PRINTED!
[1,1] element, prob = 0.0516968    (269.062,99.6875)-(687.5,540.312) batch id : 0
[2,1] element, prob = 0.0117722    (447.5,451.562)-(784.375,790) batch id : 0
[3,1] element, prob = 0.0100327    (353.75,-117.5)-(607.5,265.312) batch id : 0
[ INFO ] Image out_0.bmp created!

[0,1] element, prob = 1    (8.82812,228.438)-(205.312,409.375) batch id : 0 WILL BE PRINTED!
[1,1] element, prob = 1    (163.75,202.812)-(362.812,420.312) batch id : 0 WILL BE PRINTED!
[2,1] element, prob = 1    (390.938,292.031)-(626.562,505.625) batch id : 0 WILL BE PRINTED!
[3,1] element, prob = 1    (160.625,386.25)-(382.188,623.125) batch id : 0 WILL BE PRINTED!
[4,1] element, prob = 0.999023    (7.8125,372.188)-(173.75,577.188) batch id : 0 WILL BE PRINTED!
[5,1] element, prob = 0.99707    (282.188,120.078)-(492.188,343.438) batch id : 0 WILL BE PRINTED!
[6,1] element, prob = 0.161255    (210.312,148.359)-(433.438,392.812) batch id : 0
[7,1] element, prob = 0.152832    (165,251.562)-(284.688,350.938) batch id : 0
[8,1] element, prob = 0.0758667    (230.781,305.625)-(328.75,431.25) batch id : 0
[9,1] element, prob = 0.0470276    (251.25,177.5)-(699.375,473.125) batch id : 0
[10,1] element, prob = 0.0458679    (2.1875,287.5)-(180.625,483.75) batch id : 0
[11,1] element, prob = 0.0388184    (219.062,294.375)-(510.938,445.625) batch id : 0
[12,1] element, prob = 0.0379333    (1.09375,404.062)-(52.1094,500.938) batch id : 0
[13,1] element, prob = 0.0323792    (89.0625,223.75)-(275.312,406.875) batch id : 0
[14,1] element, prob = 0.0202637    (295,202.969)-(451.25,503.75) batch id : 0
[15,1] element, prob = 0.0196075    (71.4844,375.938)-(289.062,617.812) batch id : 0
[16,1] element, prob = 0.0182953    (232.344,380)-(701.25,651.875) batch id : 0
[17,1] element, prob = 0.0160522    (393.75,131.875)-(618.125,342.5) batch id : 0
[18,1] element, prob = 0.0159302    (142.969,233.75)-(244.531,336.25) batch id : 0
[19,1] element, prob = 0.0155487    (288.125,263.438)-(371.875,375.938) batch id : 0
[20,1] element, prob = 0.0140076    (-69.6875,386.562)-(381.25,660.625) batch id : 0
[21,1] element, prob = 0.0131454    (154.375,432.5)-(478.75,731.875) batch id : 0
[ INFO ] Image out_0.bmp created!

[0,1] element, prob = 0.996094    (121.719,351.25)-(176.25,428.125) batch id : 0 WILL BE PRINTED!
[1,1] element, prob = 0.992188    (113.281,429.375)-(184.844,495) batch id : 0 WILL BE PRINTED!
[2,1] element, prob = 0.984375    (455.938,439.062)-(536.562,492.188) batch id : 0 WILL BE PRINTED!
[3,1] element, prob = 0.9375    (187.969,479.062)-(231.094,557.188) batch id : 0 WILL BE PRINTED!
[4,1] element, prob = 0.821289    (399.375,467.5)-(468.75,521.875) batch id : 0 WILL BE PRINTED!
[5,1] element, prob = 0.808105    (14.6289,246.094)-(61.7969,321.875) batch id : 0 WILL BE PRINTED!
[6,1] element, prob = 0.79834    (365.938,307.031)-(435.938,351.562) batch id : 0 WILL BE PRINTED!
[7,1] element, prob = 0.79834    (220.625,330)-(282.812,389.375) batch id : 0 WILL BE PRINTED!
[8,1] element, prob = 0.613281    (334.375,97.1094)-(383.75,157.266) batch id : 0 WILL BE PRINTED!
[9,1] element, prob = 0.605957    (526.562,187.5)-(584.062,233.125) batch id : 0 WILL BE PRINTED!
[10,1] element, prob = 0.588867    (116.016,209.531)-(181.875,247.969) batch id : 0 WILL BE PRINTED!
[11,1] element, prob = 0.577148    (228.125,290.469)-(287.5,336.25) batch id : 0 WILL BE PRINTED!
[12,1] element, prob = 0.562012    (371.25,343.75)-(427.5,393.75) batch id : 0 WILL BE PRINTED!
[13,1] element, prob = 0.503906    (484.375,288.594)-(558.125,338.125) batch id : 0 WILL BE PRINTED!
[14,1] element, prob = 0.466797    (421.25,497.5)-(485.625,551.25) batch id : 0
[15,1] element, prob = 0.459229    (515.625,245.469)-(568.75,285.469) batch id : 0
[16,1] element, prob = 0.364746    (301.406,256.25)-(349.375,305.938) batch id : 0
[17,1] element, prob = 0.267334    (564.688,214.219)-(627.188,251.094) batch id : 0
[18,1] element, prob = 0.256836    (56.0547,349.062)-(95.8594,397.812) batch id : 0
[19,1] element, prob = 0.222656    (57.8125,137.734)-(99.7656,199.688) batch id : 0
[20,1] element, prob = 0.204346    (82.1875,53.5156)-(126.094,98.9062) batch id : 0
[21,1] element, prob = 0.169922    (379.062,499.375)-(430.312,555) batch id : 0
[22,1] element, prob = 0.164551    (378.438,189.062)-(434.062,231.25) batch id : 0
[23,1] element, prob = 0.104492    (15.7227,299.062)-(61.6406,357.812) batch id : 0
[24,1] element, prob = 0.0974121    (158.75,75.4688)-(201.25,129.844) batch id : 0
[25,1] element, prob = 0.0927124    (367.188,265)-(417.188,308.125) batch id : 0
[26,1] element, prob = 0.0814819    (213.438,432.188)-(277.812,473.438) batch id : 0
[27,1] element, prob = 0.0693359    (232.5,307.812)-(285.312,361.562) batch id : 0
[28,1] element, prob = 0.0533752    (366.875,325)-(433.75,375) batch id : 0
[29,1] element, prob = 0.0352783    (421.562,481.25)-(490.312,528.125) batch id : 0
[30,1] element, prob = 0.0196075    (134.688,61.6797)-(172.031,94.8438) batch id : 0
[31,1] element, prob = 0.0181427    (480,268.125)-(535,299.688) batch id : 0
[32,1] element, prob = 0.0178528    (505,259.062)-(561.25,295.312) batch id : 0
[33,1] element, prob = 0.0167999    (50.9375,335)-(83.6719,376.25) batch id : 0
[34,1] element, prob = 0.0151367    (413.75,504.688)-(458.125,560.312) batch id : 0
[35,1] element, prob = 0.0139999    (234.688,162.188)-(726.25,476.875) batch id : 0
[36,1] element, prob = 0.0138702    (551.875,200.938)-(618.75,237.5) batch id : 0
[37,1] element, prob = 0.0133896    (298.438,404.062)-(343.438,469.688) batch id : 0
[38,1] element, prob = 0.0125275    (145.625,65.7422)-(186.25,97.0312) batch id : 0
[ INFO ] Image out_0.bmp created!

/opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_downloader/downloader.py' 
cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_downloader/
./downloader.py --print_all
sudo ./downloader.py --name face-detection-retail-0004-fp16
sudo ./downloader.py --name mobilenet-ssd

densenet-121
densenet-161
densenet-169
densenet-201
squeezenet1.0
squeezenet1.1
mtcnn-p
mtcnn-r
mtcnn-o
mobilenet-ssd
vgg19
vgg16
ssd512
ssd300
inception-resnet-v2
dilation
googlenet-v1
googlenet-v2
googlenet-v4
alexnet
ssd_mobilenet_v2_coco
resnet-50
resnet-101
resnet-152
googlenet-v3
se-inception
se-resnet-101
se-resnet-152
se-resnet-50
se-resnext-50
se-resnext-101
Sphereface
license-plate-recognition-barrier-0007
age-gender-recognition-retail-0013
age-gender-recognition-retail-0013-fp16
emotions-recognition-retail-0003
emotions-recognition-retail-0003-fp16
face-detection-adas-0001
face-detection-adas-0001-fp16
face-detection-retail-0004
face-detection-retail-0004-fp16
face-person-detection-retail-0002
face-person-detection-retail-0002-fp16
face-reidentification-retail-0071
face-reidentification-retail-0071-fp16
facial-landmarks-35-adas-0001
facial-landmarks-35-adas-0001-fp16
head-pose-estimation-adas-0001
head-pose-estimation-adas-0001-fp16
human-pose-estimation-0001
human-pose-estimation-0001-fp16
landmarks-regression-retail-0009
landmarks-regression-retail-0009-fp16
license-plate-recognition-barrier-0001
license-plate-recognition-barrier-0001-fp16
pedestrian-and-vehicle-detector-adas-0001
pedestrian-and-vehicle-detector-adas-0001-fp16
pedestrian-detection-adas-0002
pedestrian-detection-adas-0002-fp16
person-attributes-recognition-crossroad-0031
person-attributes-recognition-crossroad-0031-fp16
person-detection-action-recognition-0003
person-detection-action-recognition-0003-fp16
person-detection-retail-0001
person-detection-retail-0001-fp16
person-detection-retail-0013
person-detection-retail-0013-fp16
person-reidentification-retail-0031
person-reidentification-retail-0031-fp16
person-reidentification-retail-0076
person-reidentification-retail-0076-fp16
person-reidentification-retail-0079
person-reidentification-retail-0079-fp16
person-vehicle-bike-detection-crossroad-0078
person-vehicle-bike-detection-crossroad-0078-fp16
road-segmentation-adas-0001
road-segmentation-adas-0001-fp16
semantic-segmentation-adas-0001
semantic-segmentation-adas-0001-fp16
single-image-super-resolution-0034
single-image-super-resolution-0034-fp16
vehicle-attributes-recognition-barrier-0039
vehicle-attributes-recognition-barrier-0039-fp16
vehicle-detection-adas-0002
vehicle-detection-adas-0002-fp16
vehicle-license-plate-detection-barrier-0106
vehicle-license-plate-detection-barrier-0106-fp16

wget https://software.intel.com/file/609199/download -O SSD_GoogleNetV2_caffe.tgz && mkdir SSD_GoogleNetV2_caffe && tar -xvzf SSD_GoogleNetV2_caffe.tgz -C SSD_GoogleNetV2_caffe

/home/tegwyn/SQDT_ROOT/data/model_checkpoints/squeezeDet/model.ckpt-87000.meta
mo_tf.py --input_meta_graph <INPUT_META_GRAPH>.meta


cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_tf.py --data_type=FP16 --input_meta_graph /home/tegwyn/SQDT_ROOT/data/model_checkpoints/squeezeDet/model.ckpt-87000.meta

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_caffe.py --data_type=FP16 --input_model /media/tegwyn/2037-F6FA/SSD_WASP_02/VGG_VOC0712_SSD_300x300_iter_15005.caffemodel

[ SUCCESS ] Generated IR model.
[ SUCCESS ] XML file: /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/./VGG_VOC0712_SSD_300x300_iter_15005.xml
[ SUCCESS ] BIN file: /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/./VGG_VOC0712_SSD_300x300_iter_15005.bin
[ SUCCESS ] Total execution time: 15.82 seconds. 

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_caffe.py --data_type=FP16 --input_model /media/tegwyn/2037-F6FA/SSD_WASP_02/VGG_VOC0712_SSD_300x300_iter_24022.caffemodel

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_caffe.py --data_type=FP16 --input_model /media/tegwyn/2037-F6FA/SSD_WASP_02/VGG_VOC0712_SSD_300x300_iter_37132.caffemodel

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_caffe.py --data_type=FP16 --input_model /media/tegwyn/2037-F6FA/SSD_WASP_02/VGG_VOC0712_SSD_300x300_iter_19054.caffemodel

tegwyn@twmffat2:~$ sudo ssh -X nvidia@172.20.10.11
nvidia@tegra-ubuntu:~$ sudo ~/jetson_clocks.sh && sudo nvmodel -m0
nvidia@tegra-ubuntu:~$ export CAFFE_ROOT=/home/nvidia/caffe
nvidia@tegra-ubuntu:~$ export PYTHONPATH=/home/nvidia/caffe/python:$PYTHONPATH
nvidia@tegra-ubuntu:~$ cd $CAFFE_ROOT && python examples/ssd/ssd_pascal.py

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_caffe.py --data_type=FP16 --input_model /media/tegwyn/2037-F6FA/SSD_WASP_02/VGG_VOC0712_SSD_300x300_iter_64000.caffemodel

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_caffe.py --data_type=FP16 --input_model /media/tegwyn/2037-F6FA/wasp/wasp_train_rate_0point000025/snapshot_iter_54860.caffemodel

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_caffe.py --data_type=FP16 --log_level DEBUG --input_model /media/tegwyn/2037-F6FA/wasp/wasp_train_rate_0point000025/snapshot_iter_54860.caffemodel

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_caffe.py --data_type=FP16 --input_model /media/tegwyn/2037-F6FA/wasp/wasp_train_rate_0point000025/snapshot_iter_54860.caffemodel

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_caffe.py --data_type=FP16 --input_shape INPUT_SHAPE [1,3,640,640] --input_model /media/tegwyn/2037-F6FA/wasp/wasp_train_rate_0point000025/snapshot_iter_63300.caffemodel

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_caffe.py --data_type=FP16 --input_shape [1,3,640,640] --input_model /media/tegwyn/2037-F6FA/wasp/wasp_train_rate_0point000025/snapshot_iter_63300.caffemodel

/home/tegwyn/Desktop/TRAIN227/snapshot_iter_125650.caffemodel

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_caffe.py --data_type=FP16 --input_model /home/tegwyn/Desktop/TRAIN227/snapshot_iter_125650.caffemodel

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_caffe.py --data_type=FP16 --input_model /home/tegwyn/Desktop/TRAIN227/snapshot_iter_125650.caffemodel --input_proto /home/tegwyn/Desktop/TRAIN227/snapshot_iter_125650.prototxt

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_caffe.py --data_type=FP16 --mean_values data[59,59,59] --input_model /home/tegwyn/Desktop/TRAIN227/snapshot_iter_125650.caffemodel --input_proto /home/tegwyn/Desktop/TRAIN227/snapshot_iter_125650.prototxt

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
sudo python3 mo_caffe.py --data_type=FP16 --input_model /home/tegwyn/Desktop/TRAIN227/snapshot_iter_125650.caffemodel --input_proto /home/tegwyn/Desktop/TRAIN227/snapshot_iter_125650.prototxt

cd /opt/intel/computer_vision_sdk_2018.3.343/deployment_tools/model_optimizer/
sudo python3 mo_caffe.py --data_type=FP16 --input_model /home/tegwyn/Desktop/TRAIN227/snapshot_iter_125650.caffemodel --input_proto /home/tegwyn/Desktop/TRAIN227/snapshot_iter_125650.prototxt

cd /opt/intel/computer_vision_sdk_2018.3.343/deployment_tools/model_optimizer/
sudo python3 mo_caffe.py --data_type=FP16 --input_model /media/tegwyn/2037-F6FA/Networks/DetectNet-COCO-Dog/snapshot_iter_38600.caffemodel --input_proto /media/tegwyn/2037-F6FA/Networks/DetectNet-COCO-Dog/deploy.prototxt

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
python3 mo_caffe.py --data_type=FP16 --input_model /media/tegwyn/2037-F6FA/wasp/wasp_train_rate_0point000025/snapshot_iter_54860.caffemodel --input_proto /media/tegwyn/2037-F6FA/Networks/DetectNet-COCO-Dog/deploy.prototxt

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
sudo python3 mo_caffe.py --data_type=FP16 --input_model /media/tegwyn/2037-F6FA/wasp/wasp_train_rate_0point01/snapshot_iter_63300.caffemodel --input_proto /media/tegwyn/2037-F6FA/Networks/DetectNet-COCO-Dog/deploy.prototxt

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/
sudo python3 mo_caffe.py --data_type=FP16 --input_model /media/tegwyn/2037-F6FA/wasp/wasp_train_rate_0point01/snapshot_iter_63300.caffemodel --input_proto /media/tegwyn/2037-F6FA/wasp/wasp_train_rate_0point01/deploy.prototxt

cd ~/inference_engine_samples/intel64/Release
./object_detection_demo_ssd_async -d MYRIAD -i cam -m /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/./snapshot_iter_38600.xml

cd ~/inference_engine_samples/intel64/Release
./object_detection_demo_ssd_async -d MYRIAD -i cam -m /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/./VGG_VOC0712_SSD_300x300_iter_20211.xml  ..... WORKS !!!!!

tegwyn@twmffat2:~$ cd ~/inference_engine_samples/intel64/Releasetegwyn@twmffat2:~/inference_engine_samples/intel64/Release$ ./object_detection_demo_ssd_async -d MYRIAD -i cam -m /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/./snapshot_iter_38600.xml
InferenceEngine: 
	API version ............ 1.4
	Build .................. 19154
[ INFO ] Parsing input parameters
[ INFO ] Reading input
[ INFO ] Loading plugin

	API version ............ 1.5
	Build .................. 19154
	Description ....... myriadPlugin
[ INFO ] Loading network files
[ INFO ] Batch size is forced to  1.
[ INFO ] Checking that the inputs are as the demo expects
[ INFO ] Checking that the outputs are as the demo expects
[ ERROR ] This demo accepts networks having only one output
tegwyn@twmffat2:~/inference_engine_samples/intel64/Release$ 


<output><port id="3"><dim>1</dim><dim>4</dim><dim>40</dim><dim>40</dim></port></output>

/opt/intel/computer_vision_sdk_2018.5.445/inference_engine/samples/python_samples/object_detection_demo_yolov3.py

cd /home/tegwyn/inference_engine_samples/object_detection_demo_yolov3_async
make install

cd ~/inference_engine_samples/intel64/Release
./object_detection_demo_yolov3_async -d MYRIAD -i cam -m /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/./snapshot_iter_38600.xml

/media/tegwyn/2037-F6FA/slugs/yolo/yolo-obj_1000.weights

# model optimizer:
cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/

sudo python3 mo_tf.py --input_model /media/tegwyn/2037-F6FA/slugs/yolo/frozen_darknet_yolov3_model.pb --tensorflow_use_custom_operations_config /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/extensions/front/tf/yolo_v3.json --input_shape=[1,416,416,3] --data_type=FP32

CWFJ-W72RXCT2
https://software.intel.com/en-us/articles/OpenVINO-Install-Linux
tar -zxf l_openvino_toolkit_p_2018.5.445.tgz
cd l_openvino_toolkit_p_<version>
sudo -E ./install_cv_sdk_dependencies.sh
sudo ./install.sh

cd /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/model_optimizer/install_prerequisites
sudo ./install_prerequisites_tf.sh


cd ~/inference_engine_samples/intel64/Release
./object_detection_demo_ssd_async -d GPU -i cam -m /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/person-detection-retail-0013/FP16/person-detection-retail-0013.xml

./interactive_face_detection_demo -d CPU -m /opt/intel/computer_vision_sdk/deployment_tools/intel_models/face-detection-retail-0004/FP16/face-detection-retail-0004.xml -d_ag CPU -m_ag /opt/intel/computer_vision_sdk/deployment_tools/intel_models/age-gender-recognition-retail-0013/FP16/age-gender-recognition-retail-0013.xml -d_em CPU -m_em /opt/intel/computer_vision_sdk/deployment_tools/intel_models/emotions-recognition-retail-0003/FP16/emotions-recognition-retail-0003.xml -d_hp CPU -m_hp /opt/intel/computer_vision_sdk/deployment_tools/intel_models/head-pose-estimation-adas-0001/FP16/head-pose-estimation-adas-0001.xml 

cd /home/tegwyn/inference_engine_samples/object_detection_demo_yolov3_async
make install

cd /home/tegwyn/inference_engine_samples/intel64/Release
./object_detection_demo_yolov3_async -d MYRIAD -i cam -m /media/tegwyn/2037-F6FA/slugs/yolo/frozen_darknet_yolov3_model.xml  ...... Error

cd ~/inference_engine_samples/intel64/Release
./object_detection_demo_ssd_async -d MYRIAD -i cam -m /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/person-detection-retail-0013/FP16/person-detection-retail-0013.xml

cd ~/inference_engine_samples/intel64/Release
./object_detection_demo_ssd_async -d CPU -i cam -m /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/intel_models/person-detection-retail-0013/FP16/person-detection-retail-0013.xml








